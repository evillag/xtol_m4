---
title: "Course 4/Task 3: Develop models to predict sentiment"
author: "Esteban Villalobos Gomez"
date: "January $23_{rd}$, 2020"
output:
  html_document:
    df_print: paged
    toc: yes
  pdf_document:
    df_print: kable
    toc: yes
  html_notebook:
    highlight: tango
    theme: simplex
    toc: yes
    toc_float: true
  word_document:
    toc: yes
subtitle: "XTOL Data Analytics and Big Data program"
---

```{r include = FALSE}
library(doParallel)
library(plotly)
library(corrplot)
library(RColorBrewer)
library(caret)
library(dplyr)
library(readr)
```


Common function definitions:
```{r}
plot_correlation <- function(dataset) {
  #' Calculate the correlation among columns in the dataset
  #' and plot a heat diagram with the results
  #' @param dataset Data.frame to analyse
  #' @return correlation data
  corr_data <- cor(dataset)
  
  corrplot(corr_data, type="full", 
           order = "original",
           tl.cex = .6, 
           addCoefasPercent = TRUE,
           col=brewer.pal(n=8, name="RdYlBu"))
  return(corr_data)
}

# General EDA
describe_df <- function(name, df) {
  paste("EDA for ", name, ":")
  str(df)
  summary(df)
  paste("Number of NA values: ", sum(is.na(df)))
}

#### Preprocessing functions
remove_highly_correlated_features <- function(df) {
  corr_data <- cor(df)
  high_corr_cols <- findCorrelation(corr_data, cutoff = 0.9, verbose = FALSE, names = FALSE, exact = ncol(corr_data))
  df[high_corr_cols] <- NULL
  return(df)
}

remove_nzv <- function(df) {
  # nearZeroVar() with saveMetrics = FALSE returns an vector 
  nzv <- nearZeroVar(df, saveMetrics = FALSE) 
  str(nzv)

  # create a new data set and remove near zero variance features
  df_new <- df[,-nzv]
  str(df_new)
  return(df_new)
}


#### Execute in parallel
run_in_parallel <- function(FUN, ...) {
  # Find how many cores are on your machine
  num_cores <- detectCores() # Result = Typically 4 to 6
  
  # Create Cluster with desired number of cores. Don't use them all! Your computer is running other processes. 
  cl <- makeCluster(num_cores - 2)
  
  # Register Cluster
  registerDoParallel(cl)
  
  result <- FUN(...)
  
  # Stop Cluster. After performing your tasks, stop your cluster. 
  stopCluster(cl)
  return(result)
}

svm_train <- function(dataF, testing_data) {
  # SVM (from the e1071 package) 
  library(e1071)
  set.seed(641386945)
  system.time(res.model <- run_in_parallel(svm, iphonesentiment ~., data = dataF))
  res.predictions <- predict(res.model, testing_data) 
  res.post_resample <- postResample(res.predictions, testing_data$iphonesentiment)
  return(list("model" = res.model, "post_resample" = res.post_resample))
}

knn_train <- function(dataF, testing_data) {
  # K-nearest Neighbors (from the kknn package)
  library(kknn)
  set.seed(641386945)
  system.time(res.model <- run_in_parallel(train.kknn, iphonesentiment ~., data = dataF))
  res.predictions <- predict(res.model, testing_data) 
  res.post_resample <- postResample(res.predictions, testing_data$iphonesentiment)
  return(list("model" = res.model, "post_resample" = res.post_resample))
}

caret_train <- function(dataF, testing_data, model_name, fitCtrl) {
  set.seed(641386945)
  system.time(res.model <- run_in_parallel(train, iphonesentiment~., data = dataF, method = model_name, trControl = fitCtrl ))
  res.predictions <- predict(res.model, testing_data) 
  res.post_resample <- postResample(res.predictions, testing_data$iphonesentiment)
  return(list("model" = res.model, "post_resample" = res.post_resample))
}

```

# iPhone analysis

Load training datasets, one is for IPhone labeled sentiment, and the other one for the Samsung Galaxy phone.
```{r echo=FALSE}
iphoneDF <- read_csv("iphone_smallmatrix_labeled_8d.csv")

```

Explore structure and descriptive statistics from the training datasets
```{r echo=FALSE}
describe_df("iPhone", iphoneDF)
```
## Check the sentiment results distribution.
### iPhone sentiments 
```{r}
plot_ly(iphoneDF, x= ~iphoneDF$iphonesentiment, type='histogram')
```


## Look for any correlation in both dataframes
### iPhone correlation
Explore correlation between all variables:
```{r echo=FALSE}
# create a new data set and remove features highly correlated with the dependant 
iphoneCOR <- remove_highly_correlated_features(iphoneDF)
paste("Number of original features: ", ncol(iphoneDF))
paste("Number of features after cleanup: ", ncol(iphoneCOR))
plot_correlation(iphoneCOR)
```
Removing near zero vars:
```{r}
nzvMetrics <- nearZeroVar(iphoneCOR, saveMetrics = TRUE)
str(nzvMetrics)

iphoneNZV <- remove_nzv(iphoneCOR)

paste("NZV number of features after cleanup: ", ncol(iphoneNZV))
```
### RFE
```{r}
set.seed(9874568)
iphone_sample <- iphoneDF[sample(1:nrow(iphoneDF), 1000, replace=FALSE),]

# Set up rfeControl with randomforest, repeated cross validation and no updates
ctrl <- rfeControl(functions = rfFuncs,
                   method = "repeatedcv",
                   repeats = 5,
                   verbose = FALSE)

# Use rfe and omit the response variable (attribute 59 iphonesentiment)
rfe_results <- run_in_parallel(rfe, iphone_sample[,1:58],
                              iphone_sample$iphonesentiment,
                              sizes=(1:58), rfeControl=ctrl)

# Get results
rfe_results

# Plot results
plot(rfe_results, type=c("g", "o"))
```
Create a new dataset with the best features found by RFE
```{r}
# create new data set with rfe recommended features
iphoneRFE <- iphoneDF[,predictors(rfe_results)]

# add the dependent variable to iphoneRFE
iphoneRFE$iphonesentiment <- iphoneDF$iphonesentiment

# review outcome
str(iphoneRFE)
```


## Preprocess label and partition data
```{r}
df <- iphoneDF
df$iphonesentiment <- as.factor(df$iphonesentiment)
plot_ly(df, x= ~df$iphonesentiment, type='histogram')

set.seed(90210)
dataPar <- createDataPartition(df$iphonesentiment, p = .70, list = FALSE)
train_df <- df[dataPar,]
test_df <- df[-dataPar,]

#iphoneCOR
iphoneCOR$iphonesentiment <- as.factor(iphoneCOR$iphonesentiment)
set.seed(90210)
dataParCOR <- createDataPartition(iphoneCOR$iphonesentiment, p = .70, list = FALSE)
train_dfCOR <- iphoneCOR[dataParCOR,]
test_dfCOR <- iphoneCOR[-dataParCOR,]

#iphoneRFE
iphoneRFE$iphonesentiment <- as.factor(iphoneRFE$iphonesentiment)
set.seed(90210)
dataParRFE <- createDataPartition(iphoneRFE$iphonesentiment, p = .70, list = FALSE)
train_dfRFE <- iphoneRFE[dataParRFE,]
test_dfRFE <- iphoneRFE[-dataParRFE,]

#iphoneNZV
iphoneNZV$iphonesentiment <- as.factor(iphoneNZV$iphonesentiment)
set.seed(90210)
dataParNZV <- createDataPartition(iphoneNZV$iphonesentiment, p = .70, list = FALSE)
train_dfNZV <- iphoneNZV[dataParNZV,]
test_dfNZV <- iphoneNZV[-dataParNZV,]

```
## CV (Cross Validation) and Modeling
```{r}
# cross validation 
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 2)
```

### C5.0
```{r}
##### Decision Tree (C5.0) #####
print("C5.0: Full Dataset")
dt_c50 <- caret_train(df, test_df, 'C5.0', fitControl)
dt_c50["model"]
dt_c50["post_resample"]
```
Train model with RFE dataset:
```{r}
print("C5.0: RFE")
dt_c50_rfe <- caret_train(iphoneRFE, test_dfRFE, 'C5.0', fitControl)
dt_c50_rfe["model"]
dt_c50_rfe["post_resample"]
```
Train model with NZV dataset:
```{r}
print("C5.0: NZV")
dt_c50_nzv <- caret_train(iphoneNZV, test_dfNZV, 'C5.0', fitControl)
dt_c50_nzv["model"]
dt_c50_nzv["post_resample"]
```
Train model with COR dataset:
```{r}
print("C5.0: COR")
dt_c50_cor <- caret_train(iphoneCOR, test_dfCOR, 'C5.0', fitControl)
dt_c50_cor["model"]
dt_c50_cor["post_resample"]
```

### Random Forest
```{r}
print("Random Forest: Full Dataset")
rf <- caret_train(df, test_df, 'rf', fitControl)
rf["model"]
rf["post_resample"]

print("Random Forest: RFE")
rf_rfe <- caret_train(iphoneRFE, test_dfRFE, 'rf', fitControl)
rf_rfe["model"]
rf_rfe["post_resample"]

print("Random Forest: NZV")
rf_nzv <- caret_train(iphoneNZV, test_dfNZV, 'rf', fitControl)
rf_nzv["model"]
rf_nzv["post_resample"]

print("Random Forest: COR")
rf_cor <- caret_train(iphoneCOR, test_dfCOR, 'rf', fitControl)
rf_cor["model"]
rf_cor["post_resample"]
```


### Support Vector Machine
```{r}
print("SVM: Full Dataset")
svm_train_full <- svm_train(df, test_df)
svm_train_full["model"]
svm_train_full["post_resample"]

print("SVM: RFE")
svm_train_rfe <- svm_train(iphoneRFE, test_dfRFE)
svm_train_rfe["model"]
svm_train_rfe["post_resample"]

print("SVM: NZV")
svm_train_nzv <- svm_train(iphoneNZV, test_dfNZV)
svm_train_nzv["model"]
svm_train_nzv["post_resample"]

print("SVM: COR")
svm_train_cor <- svm_train(iphoneCOR, test_dfCOR)
svm_train_cor["model"]
svm_train_cor["post_resample"]

```
## K-nearest Neighbors (from the kknn package)
```{r}
print("KNN: Full Dataset")
knn_train_full <- knn_train(df, test_df)
knn_train_full["model"]
knn_train_full["post_resample"]

print("KNN: RFE")
knn_train_rfe <- knn_train(iphoneRFE, test_dfRFE)
knn_train_rfe["model"]
knn_train_rfe["post_resample"]

print("KNN: NZV")
knn_train_nzv <- knn_train(iphoneNZV, test_dfNZV)
knn_train_nzv["model"]
knn_train_nzv["post_resample"]

print("KNN: COR")
knn_train_cor <- knn_train(iphoneCOR, test_dfCOR)
knn_train_cor["model"]
knn_train_cor["post_resample"]
```

```{r}
# TODO: replace with correct models
# Creating confusion matrix
cm_dt <- confusionMatrix(pdt, test_df$iphonesentiment) 
cm_dt

#cmRF <- confusionMatrix(prf, test_df$iphonesentiment) 
#cmRF

cmsvm <- confusionMatrix(psvm, test_df$iphonesentiment) 
cmsvm

cmknn <- confusionMatrix(pknn, test_df$iphonesentiment) 
cmknn

# Grouped bar chart to evaluate model performance
#Eval <- c(post_c50, post_rf, post_svm, post_knn)
Eval <- c(post_c50, post_svm, post_knn)
barplot(Eval, main = "Model Evaluation", col = c("darkblue","red"))
```
Pre processing the large datatset 
```{r}
large_df <- read_csv("big_matrix.csv")
#str(large_df)

large_df$id <- NULL
# create new data set with rfe recommended features
large_df <- large_df[,predictors(rfe_results)]
# review outcome
str(large_df)

```

Apply Model on the large dataset
```{r}
options(max.print=1000000)

large_df$iphonesentiment<- predict(rf_rfe["model"], large_df)
head(large_df$iphonesentiment, 5)
summary(large_df$iphonesentiment)
```

-----------------------------------------------------------------
```{r}
predicted <- predict(rf_rfe["model"], head(large_df, 20000))
predicted
#large_df$iphonesentiment<- predict(rf_rfe["model"], large_df)
#head(large_df$iphonesentiment, 5)
#summary(large_df$iphonesentiment)
```


--EOF--